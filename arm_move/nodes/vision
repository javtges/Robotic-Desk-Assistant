#!/usr/bin/env python
'''
Creates 3 services to move the arm to various positions (Waypoints).

No publishers or subscribers in this node.

SERVICES:
  + /px100/reset ~ Moves the arm to the home position, and spawns an Intel Realsense box into the Rviz scene in a defined location. Has an option to clear all the waypoints in the parameter server.
  + /px100/step ~ Moves the gripper to the desired xyz position, with a desired gripper state (open/closed). If movement is possible, it is executed and added to the waypoints list. Otherwise an errorcode is returned.
  + /px100/follow ~ Moves the gripper sequentially to the waypoints in the parameter server. If the repeat setting is true, it continues this loop until commanded to stop.

PARAMETERS:
  + /px100/waypoints ~ A list of waypoints [x,y,z,gripper_state]. This in the launchfile is initially loaded from a YAML file, though can be cleared with the /px100/reset service.

'''

import sys
import copy

import rospy
import moveit_commander
import moveit_msgs.msg
import geometry_msgs.msg
from std_msgs.msg import String
from std_srvs.srv import Empty, EmptyResponse
from moveit_commander.conversions import pose_to_list
from interbotix_xs_modules.arm import InterbotixManipulatorXS
from arm_move.srv import step, follow, reset, resetResponse

from cv_bridge import CvBridge, CvBridgeError
from sensor_msgs.msg import Image, CompressedImage
import numpy as np
import cv2
import pyrealsense2 as rs


class Vision:

    def __init__(self):

        moveit_commander.roscpp_initialize(sys.argv)
        rospy.init_node("vision", anonymous=True, log_level=rospy.DEBUG)

        rospy.logerr("started the node")

        rospy.Subscriber("/camera/aligned_depth_to_color/image_raw", Image, callback=self.convert_depth_image, queue_size=1)
        rospy.Subscriber("/camera/color/image_raw", Image, callback=self.convert_color_image, queue_size=1)

        rospy.logerr('subscribed')
        self.first_frame = True

    def show_video(self,window_name,ros_image):
        cv2.imshow(window_name,ros_image)
        cv2.waitKey(3)

    def convert_depth_image(self,ros_image):
        bridge = CvBridge()
        # Use cv_bridge() to convert the ROS image to OpenCV format
        try:
            self.depth_image = bridge.imgmsg_to_cv2(ros_image)
            # depth_array = np.array(self.depth_image, dtype=np.float32)

        except CvBridgeError:
            print(CvBridgeError())
            rospy.logerr("bad")

    def convert_color_image(self,ros_image):
        bridge = CvBridge()
        try:
            self.bgr_image = bridge.imgmsg_to_cv2(ros_image)
            self.hsv_image = cv2.cvtColor(self.bgr_image, cv2.COLOR_BGR2HSV)
            self.rgb_image = cv2.cvtColor(self.bgr_image, cv2.COLOR_BGR2RGB)
            self.grayscale_image = cv2.cvtColor(self.bgr_image, cv2.COLOR_BGR2GRAY)

            self.find_objects()

        except CvBridgeError:
            print(CvBridgeError())
            rospy.logerr("bad")


    def find_objects(self):
        '''
        Prompts the user to select a background area.
        
        OR
        Canny edge detection into contour recognition - not sure how well it works
        # '''

        # if self.first_frame:
        #     self.first_grayscale = self.grayscale_image
        #     self.first_frame = False
        #     rospy.logerr("first frame set")
        gauss_color = cv2.GaussianBlur(self.rgb_image, (3,3), cv2.BORDER_DEFAULT)

        chans = cv2.split(gauss_color)
        canny_img = np.zeros(chans[0].shape)        

        # for channel in chans:
        #     canny_int = cv2.Canny(channel, 150, 200, 3, L2gradient = True)
        #     canny_img = cv2.bitwise_or(canny_img, canny_int)

        canny_img = cv2.Canny(self.grayscale_image,80,150, 3, L2gradient = True)
        
        # self.compared_gray = cv2.compare(self.first_grayscale, self.grayscale_image, cv2.CMP_NE)

        self.show_video("compared", canny_img)

        # self.show_video("grayscale", self.grayscale_image)
        # blurred_grayscale = cv2.GaussianBlur(self.grayscale_image, (7,7), 1)

        # thresh = cv2.threshold(canny_img, 150, 255, cv2.THRESH_BINARY)
        contours, hierarchy = cv2.findContours(canny_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        hull_list = []

        for i in range(len(contours)):
            hull = cv2.convexHull(contours[i])
            hull_list.append(hull)


        contours_by_area = sorted(contours, key=cv2.contourArea, reverse=True)
        hulls_by_area = sorted(hull_list, key=cv2.contourArea, reverse=True)

        object_locations = []

        for cnt in range(4):
            M = cv2.moments(contours_by_area[cnt])
            cx = int(M['m10']/M['m00'])
            cy = int(M['m01']/M['m00'])

            location = self.get_xyz_from_image(self.depth_image, cx, cy)

            object_locations.append(location)


        # rospy.logerr(contours.shape)

        cv2.drawContours(self.rgb_image, contours_by_area, 0, (0,255,0), 3)
        # cv2.drawContours(self.rgb_image, contours_by_area, 1, (0,255,0), 3)
        # cv2.drawContours(self.rgb_image, contours_by_area, 2, (0,255,0), 3)
        # cv2.drawContours(self.rgb_image, contours_by_area, 3, (0,255,0), 3)

        cv2.drawContours(self.rgb_image, hulls_by_area, 0, (255,255,0), 3)
        # cv2.drawContours(self.rgb_image, hulls_by_area, 3, (255,255,0), 3)
        # cv2.drawContours(self.rgb_image, hulls_by_area, 2, (255,255,0), 3)
        # cv2.drawContours(self.rgb_image, hulls_by_area, 1, (255,255,0), 3)


        rospy.logdebug(object_locations[0])

        self.show_video("contours", self.rgb_image)

        


    def find_finger_vector(self):
        pass



    def get_xyz_from_image(self,depth_image, x,y):
        intr = rs.intrinsics()
        intr.width = 1280
        intr.height = 720
        intr.ppx = 651.0391845703125
        intr.ppy = 354.0467834472656
        intr.fx = 921.5665283203125
        intr.fy = 921.62841796875
        intr.model = rs.distortion.none #"plumb_bob"
        intr.coeffs = [0.0, 0.0, 0.0, 0.0, 0.0]

        result = rs.rs2_deproject_pixel_to_point(intr, [x,y], depth_image[y,x])
        return result 



if __name__ == '__main__':
    ''' The main() function. '''
    Vision()
    rospy.spin()